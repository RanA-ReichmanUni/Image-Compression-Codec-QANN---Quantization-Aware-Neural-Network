{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XmgKNqovPmj"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers\n",
        "!pip uninstall jax jaxlib -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzeZO8Ft2RMI",
        "outputId": "894f9944-854f-4418-cf0d-7a85bf6d3ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.30.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.24.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.8.30)\n",
            "Downloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "Successfully installed diffusers-0.30.3\n",
            "Found existing installation: jax 0.4.33\n",
            "Uninstalling jax-0.4.33:\n",
            "  Successfully uninstalled jax-0.4.33\n",
            "Found existing installation: jaxlib 0.4.33\n",
            "Uninstalling jaxlib-0.4.33:\n",
            "  Successfully uninstalled jaxlib-0.4.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yN5VOMILCzV",
        "outputId": "903459b8-8d0e-4934-b791-e2de0a3f836b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0e7a5ed8e1404b29b6ef141ea67822ac",
            "d9e649f6b9fe458e9c1b68da0d752fae",
            "2d513d9a86f1475bb40e5ad2710f53f9",
            "279771b7681a493fa698809789cb7ecd",
            "3d34778cd5b84fb5893fbe20490d20fc",
            "9028bb792b4047d4a78ba10a93b36ead",
            "410617b4ea284efbbf36a78f3133c405",
            "ee8b69b045bf40929d17b0e6c09be2a0",
            "536444cfc5e2463c94fb8c19dbc9fd1a",
            "8d882cdf46c54a1aba6d18d3d1d3ebf5",
            "4b69025066174a13bcff238daa54ba8a",
            "dce79b46483b418798ed4f4f48360fe9",
            "6e80373e39aa47bf944b4ba27fda1fe7",
            "f40ea1032f83410f855ddea89973b8d5",
            "fe8349ab01ef49299884d0a7f37cdb1d",
            "5bfc9135090144c6936dca684261b079",
            "3fadb8b52c3c4492a0beacfb5fefd908",
            "87203380c93a4086a625aef6933a822b",
            "51d3e6c21c1448cf86b9ac4f0eaff524",
            "4d4c58435ba44ab3b72867c13cb22722",
            "02802c36ea1443edacbea197ae4bac92",
            "615496d1907c49f5b00860888fbb942e",
            "c72a6cc209d14ea480137fa180af31f3",
            "fbee40da388145ebab51b45fbbdf94aa",
            "dd2c26eaf1fb487198ade76403496577",
            "9a5edd738827425f898bfbb1069cfec2",
            "818e963e00c7483d93380657eae7c1ee",
            "a330cbc3cd5a44fd95ca10f1d8ea8361",
            "a7c299b82ed147c2b3f8ac195463d068",
            "9aac18aa6f1d4e36a02932f4730690db",
            "b11b4d1fbec643629340e75809129b8d",
            "ddabe319697641ebbec2f5c0a52aa500",
            "58d20436267748bc838c64b9e95ecf6e"
          ]
        },
        "id": "E_UtTDzoYh9q",
        "outputId": "a9415498-9051-49f9-e0da-d36f4848fca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7a5ed8e1404b29b6ef141ea67822ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dce79b46483b418798ed4f4f48360fe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c72a6cc209d14ea480137fa180af31f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoencoderKL(\n",
              "  (encoder): Encoder(\n",
              "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (down_blocks): ModuleList(\n",
              "      (0): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0-1): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (downsamplers): ModuleList(\n",
              "          (0): Downsample2D(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (downsamplers): ModuleList(\n",
              "          (0): Downsample2D(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (downsamplers): ModuleList(\n",
              "          (0): Downsample2D(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0-1): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (mid_block): UNetMidBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0): Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "    (conv_act): SiLU()\n",
              "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (up_blocks): ModuleList(\n",
              "      (0-1): 2 x UpDecoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0-2): 3 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (upsamplers): ModuleList(\n",
              "          (0): Upsample2D(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): UpDecoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (upsamplers): ModuleList(\n",
              "          (0): Upsample2D(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): UpDecoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (mid_block): UNetMidBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0): Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "    (conv_act): SiLU()\n",
              "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Much better vae module\n",
        "# Load VAE model\n",
        "from diffusers import AutoencoderKL\n",
        "device = \"cuda:0\"\n",
        "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\").to(device)\n",
        "vae.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hy2hwqrOZY"
      },
      "source": [
        "# Residual UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e0WA1norReK",
        "outputId": "8995b109-af80-43d8-ccfb-95581a95d3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.30.3)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.24.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.4.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, ftfy, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 ftfy-6.2.3 optuna-4.0.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading COCO annotations...\n",
            "Extracting COCO annotations...\n",
            "loading annotations into memory...\n",
            "Done (t=18.67s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:07<00:00, 73.0MB/s]\n",
            "<ipython-input-4-3456f19bdb63>:344: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "<ipython-input-4-3456f19bdb63>:350: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "  0%|          | 0/282 [00:00<?, ?it/s]<ipython-input-4-3456f19bdb63>:366: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Training Loss: 0.082638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-4-3456f19bdb63>:422: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Training Loss: 0.082638, Validation Loss: 0.083205\n",
            "Best model saved at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Training Loss: 0.081595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Training Loss: 0.081595, Validation Loss: 0.082686\n",
            "Best model saved at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50], Training Loss: 0.081510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50], Training Loss: 0.081510, Validation Loss: 0.082855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/50], Training Loss: 0.081672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/50], Training Loss: 0.081672, Validation Loss: 0.082810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50], Training Loss: 0.081660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50], Training Loss: 0.081660, Validation Loss: 0.083455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/50], Training Loss: 0.081691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/50], Training Loss: 0.081691, Validation Loss: 0.082444\n",
            "Best model saved at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/50], Training Loss: 0.081424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/50], Training Loss: 0.081424, Validation Loss: 0.083096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/50], Training Loss: 0.081585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/50], Training Loss: 0.081585, Validation Loss: 0.082494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/50], Training Loss: 0.081594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/50], Training Loss: 0.081594, Validation Loss: 0.082512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Training Loss: 0.081360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Training Loss: 0.081360, Validation Loss: 0.082957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/50], Training Loss: 0.081476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/50], Training Loss: 0.081476, Validation Loss: 0.083186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/50], Training Loss: 0.081559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/50], Training Loss: 0.081559, Validation Loss: 0.082623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/50], Training Loss: 0.081068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/50], Training Loss: 0.081068, Validation Loss: 0.082551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/50], Training Loss: 0.080943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/50], Training Loss: 0.080943, Validation Loss: 0.082726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/50], Training Loss: 0.080903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/50], Training Loss: 0.080903, Validation Loss: 0.082078\n",
            "Best model saved at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:35<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/50], Training Loss: 0.080958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/50], Training Loss: 0.080958, Validation Loss: 0.082532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/50], Training Loss: 0.081031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/50], Training Loss: 0.081031, Validation Loss: 0.081749\n",
            "Best model saved at epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/50], Training Loss: 0.081029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/50], Training Loss: 0.081029, Validation Loss: 0.082149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/50], Training Loss: 0.080875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/50], Training Loss: 0.080875, Validation Loss: 0.082033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/50], Training Loss: 0.081038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/50], Training Loss: 0.081038, Validation Loss: 0.082075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/50], Training Loss: 0.080881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/50], Training Loss: 0.080881, Validation Loss: 0.082166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/50], Training Loss: 0.081019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/50], Training Loss: 0.081019, Validation Loss: 0.082364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/50], Training Loss: 0.080981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/50], Training Loss: 0.080981, Validation Loss: 0.082211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/50], Training Loss: 0.080622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/50], Training Loss: 0.080622, Validation Loss: 0.081347\n",
            "Best model saved at epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/50], Training Loss: 0.080822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/50], Training Loss: 0.080822, Validation Loss: 0.081650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/50], Training Loss: 0.080641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/50], Training Loss: 0.080641, Validation Loss: 0.082209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/50], Training Loss: 0.080613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/50], Training Loss: 0.080613, Validation Loss: 0.081903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/50], Training Loss: 0.080476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/50], Training Loss: 0.080476, Validation Loss: 0.082206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/50], Training Loss: 0.080587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/50], Training Loss: 0.080587, Validation Loss: 0.081458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/50], Training Loss: 0.080688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/50], Training Loss: 0.080688, Validation Loss: 0.082018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/50], Training Loss: 0.080567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/50], Training Loss: 0.080567, Validation Loss: 0.081679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/50], Training Loss: 0.080504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/50], Training Loss: 0.080504, Validation Loss: 0.081325\n",
            "Best model saved at epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/50], Training Loss: 0.080478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/50], Training Loss: 0.080478, Validation Loss: 0.081083\n",
            "Best model saved at epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/50], Training Loss: 0.080578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/50], Training Loss: 0.080578, Validation Loss: 0.081300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/50], Training Loss: 0.080469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/50], Training Loss: 0.080469, Validation Loss: 0.081367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/50], Training Loss: 0.080315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/50], Training Loss: 0.080315, Validation Loss: 0.081455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/50], Training Loss: 0.080494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/50], Training Loss: 0.080494, Validation Loss: 0.081385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/50], Training Loss: 0.080631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/50], Training Loss: 0.080631, Validation Loss: 0.081124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/50], Training Loss: 0.080463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/50], Training Loss: 0.080463, Validation Loss: 0.081433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/50], Training Loss: 0.080075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/50], Training Loss: 0.080075, Validation Loss: 0.081336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/50], Training Loss: 0.080364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/50], Training Loss: 0.080364, Validation Loss: 0.081343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/50], Training Loss: 0.080400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/50], Training Loss: 0.080400, Validation Loss: 0.081492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/50], Training Loss: 0.080436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/50], Training Loss: 0.080436, Validation Loss: 0.081149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/50], Training Loss: 0.080364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/50], Training Loss: 0.080364, Validation Loss: 0.081629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/50], Training Loss: 0.080286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/50], Training Loss: 0.080286, Validation Loss: 0.081543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/50], Training Loss: 0.080365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/50], Training Loss: 0.080365, Validation Loss: 0.081496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/50], Training Loss: 0.080233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/50], Training Loss: 0.080233, Validation Loss: 0.081485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:34<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/50], Training Loss: 0.080218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/50], Training Loss: 0.080218, Validation Loss: 0.081694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/50], Training Loss: 0.080378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/50], Training Loss: 0.080378, Validation Loss: 0.081203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282/282 [05:33<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50], Training Loss: 0.080383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50], Training Loss: 0.080383, Validation Loss: 0.081530\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries (if not already installed)\n",
        "!pip install ftfy pycocotools diffusers optuna\n",
        "\n",
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg19\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "import logging\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from diffusers import AutoencoderKL\n",
        "import random\n",
        "import zipfile\n",
        "import requests\n",
        "from pycocotools.coco import COCO\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "model_path = \"Models/PixelLevelRestorationVAECont2.3\"\n",
        "\n",
        "# Set up logging\n",
        "log_file = f'/content/drive/MyDrive/{model_path}/training_log.txt'\n",
        "os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
        "logging.basicConfig(\n",
        "    filename=log_file,\n",
        "    filemode='w',\n",
        "    format='%(asctime)s %(levelname)s:%(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load VAE Model\n",
        "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\").to(device)\n",
        "vae.eval()\n",
        "for param in vae.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Download COCO Training Images\n",
        "data_dir = '/content/coco_data'\n",
        "annotations_dir = '/content/coco_annotations'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "os.makedirs(annotations_dir, exist_ok=True)\n",
        "\n",
        "# Download COCO annotations\n",
        "annotations_url = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "annotations_zip = 'annotations_trainval2017.zip'\n",
        "\n",
        "if not os.path.exists(os.path.join(annotations_dir,'instances_train2017.json')):\n",
        "    print('Downloading COCO annotations...')\n",
        "    response = requests.get(annotations_url, stream=True)\n",
        "    with open(annotations_zip, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print('Extracting COCO annotations...')\n",
        "    with zipfile.ZipFile(annotations_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(annotations_dir)\n",
        "    os.remove(annotations_zip)\n",
        "else:\n",
        "    print('COCO annotations already downloaded.')\n",
        "\n",
        "# Function to download a single image\n",
        "def download_image(img_data, save_dir):\n",
        "    img_url = img_data['coco_url']\n",
        "    img_name = os.path.join(save_dir, img_data['file_name'])\n",
        "\n",
        "    if not os.path.exists(img_name):\n",
        "        try:\n",
        "            response = requests.get(img_url, stream=True)\n",
        "            if response.status_code == 200:\n",
        "                with open(img_name, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=1024):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                logging.info(f\"Downloaded {img_name}\")\n",
        "            else:\n",
        "                logging.error(f\"Failed to download {img_name}: HTTP {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to download {img_name}: {e}\")\n",
        "    else:\n",
        "        logging.info(f\"Image {img_name} already exists, skipping download.\")\n",
        "\n",
        "# Function to download images using parallel downloading\n",
        "def download_random_coco_images(num_images=10000, save_dir='/content/coco_data'):\n",
        "    coco = COCO('/content/coco_annotations/annotations/instances_train2017.json')\n",
        "    image_ids = coco.getImgIds()\n",
        "    random_ids = random.sample(image_ids, num_images)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "        for img_id in random_ids:\n",
        "            img_data = coco.loadImgs(img_id)[0]\n",
        "            futures.append(executor.submit(download_image, img_data, save_dir))\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            future.result()\n",
        "\n",
        "# Download images if not already done\n",
        "if not os.listdir(data_dir):\n",
        "    logging.info(\"Downloading COCO images...\")\n",
        "    download_random_coco_images(num_images=10000, save_dir=data_dir)\n",
        "else:\n",
        "    logging.info(\"COCO images already downloaded.\")\n",
        "\n",
        "# Quantize functions (operate in latent space)\n",
        "def quantize_batch(latents, parameters):\n",
        "    parameters = parameters.view(-1, 1, 1, 1)\n",
        "    quantized_latents = (latents / (255 * parameters) + 0.5).clamp(0, 1)\n",
        "    quantized = (quantized_latents * 255.0 + 0.5).clamp(0, 255).type(torch.uint8)\n",
        "    quantized = quantized.float() / 127.5 - 1\n",
        "    return quantized\n",
        "\n",
        "def unquantize_batch(quantized, parameters):\n",
        "    parameters = parameters.view(-1, 1, 1, 1)\n",
        "    unquantized = (quantized + 1) * 127.5\n",
        "    unquantized = unquantized / 255.0\n",
        "    unquantized_latents = (unquantized - 0.5) * (255 * parameters)\n",
        "    return unquantized_latents.to(quantized.device)\n",
        "\n",
        "# Custom Dataset Class with Smart Cropping\n",
        "class VAEDataset(Dataset):\n",
        "    def __init__(self, image_dir, parameters, crop_size=256, transform=None):\n",
        "        self.image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('.jpg', '.png'))])\n",
        "        self.parameters = parameters\n",
        "        self.crop_size = crop_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths) * len(self.parameters)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_idx = idx // len(self.parameters)\n",
        "        param_idx = idx % len(self.parameters)\n",
        "        parameter = self.parameters[param_idx]\n",
        "        parameter = torch.tensor([parameter], dtype=torch.float32)\n",
        "\n",
        "        image_path = self.image_paths[img_idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(self.crop_size, self.crop_size))\n",
        "        image = image[:, i:i+h, j:j+w]\n",
        "\n",
        "        return image, parameter\n",
        "class ConditionalResize:\n",
        "    def __init__(self, min_size):\n",
        "        self.min_size = min_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if min(w, h) < self.min_size:\n",
        "            img = transforms.Resize(self.min_size)(img)\n",
        "        return img\n",
        "# Data Transformation with Enhanced Augmentation\n",
        "transform = transforms.Compose([\n",
        "    ConditionalResize(144),\n",
        "    transforms.RandomResizedCrop(128, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.02),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Paths to images\n",
        "image_dir = '/content/coco_data'\n",
        "\n",
        "# List of parameter values with variability\n",
        "parameters = [0.58215, 0.78215, 0.98215]\n",
        "\n",
        "# Dataset and DataLoader\n",
        "crop_size = 128\n",
        "dataset = VAEDataset(image_dir, parameters, crop_size=crop_size, transform=transform)\n",
        "\n",
        "# Use a subset of data if needed\n",
        "subset_size = 10000\n",
        "dataset = torch.utils.data.Subset(dataset, range(subset_size))\n",
        "\n",
        "# Split Dataset into Training and Validation Sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Adjusted batch size for memory constraints\n",
        "batch_size = 32  # Reduced batch size due to increased memory usage\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define Self-Attention Block\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.query_conv = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_dim, in_dim, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, C, width, height = x.size()\n",
        "        proj_query = self.query_conv(x).view(batch, -1, width * height).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(batch, -1, width * height)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = self.softmax(energy)\n",
        "        proj_value = self.value_conv(x).view(batch, -1, width * height)\n",
        "\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, C, width, height)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "# Define U-Net with Attention and Parameter Embedding\n",
        "class UNetWithParams(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):  # Adjusted channels for images\n",
        "        super(UNetWithParams, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        self.param_fc = nn.Linear(1, 16)\n",
        "\n",
        "        self.enc1 = self.conv_block(in_channels + 16, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.att1 = SelfAttention(128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "\n",
        "        self.bottleneck = self.conv_block(512, 1024)\n",
        "\n",
        "        self.dec4 = self.up_conv(1024, 512)\n",
        "        self.dec4_conv = self.conv_block(1024, 512)\n",
        "\n",
        "        self.dec3 = self.up_conv(512, 256)\n",
        "        self.dec3_conv = self.conv_block(512, 256)\n",
        "        self.att2 = SelfAttention(256)\n",
        "\n",
        "        self.dec2 = self.up_conv(256, 128)\n",
        "        self.dec2_conv = self.conv_block(256, 128)\n",
        "\n",
        "        self.dec1 = self.up_conv(128, 64)\n",
        "        self.dec1_conv = self.conv_block(128, 64)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def up_conv(self, in_channels, out_channels):\n",
        "        up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        return up\n",
        "\n",
        "    def forward(self, x, params):\n",
        "        # Embed parameters\n",
        "        param_embedding = self.param_fc(params)\n",
        "        param_embedding = param_embedding.view(-1, 16, 1, 1)\n",
        "        param_embedding = param_embedding.expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat((x, param_embedding), dim=1)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(F.max_pool2d(e1, 2))\n",
        "        e2 = self.att1(e2)\n",
        "        e3 = self.enc3(F.max_pool2d(e2, 2))\n",
        "        e4 = self.enc4(F.max_pool2d(e3, 2))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(F.max_pool2d(e4, 2))\n",
        "\n",
        "        # Decoder\n",
        "        d4 = self.dec4(b)\n",
        "        d4 = torch.cat((d4, e4), dim=1)\n",
        "        d4 = self.dec4_conv(d4)\n",
        "\n",
        "        d3 = self.dec3(d4)\n",
        "        d3 = torch.cat((d3, e3), dim=1)\n",
        "        d3 = self.dec3_conv(d3)\n",
        "        d3 = self.att2(d3)\n",
        "\n",
        "        d2 = self.dec2(d3)\n",
        "        d2 = torch.cat((d2, e2), dim=1)\n",
        "        d2 = self.dec2_conv(d2)\n",
        "\n",
        "        d1 = self.dec1(d2)\n",
        "        d1 = torch.cat((d1, e1), dim=1)\n",
        "        d1 = self.dec1_conv(d1)\n",
        "\n",
        "        out = self.final_conv(d1)\n",
        "        return out\n",
        "\n",
        "# Initialize model\n",
        "model = UNetWithParams().to(device)\n",
        "\n",
        "# Loss Functions\n",
        "criterion_mse = nn.MSELoss()\n",
        "\n",
        "# Perceptual Loss (VGG19)\n",
        "vgg = vgg19(pretrained=True).features[:12].to(device).eval()\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "def perceptual_loss(output, target):\n",
        "    output_features = vgg(output)\n",
        "    target_features = vgg(target)\n",
        "    return F.l1_loss(output_features, target_features)\n",
        "\n",
        "# Multi-Scale Loss\n",
        "def multi_scale_loss(output, target):\n",
        "    loss = 0\n",
        "    for scale in [1, 0.5, 0.25]:\n",
        "        scaled_output = F.interpolate(output, scale_factor=scale, mode='bilinear', align_corners=False)\n",
        "        scaled_target = F.interpolate(target, scale_factor=scale, mode='bilinear', align_corners=False)\n",
        "        loss += F.mse_loss(scaled_output, scaled_target)\n",
        "    return loss\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "\n",
        "# Path to your saved checkpoint\n",
        "checkpoint_path = '/content/drive/MyDrive/Models/PixelLevelRestorationVAECont2.2/unet_best_checkpoint.pth'\n",
        "\n",
        "# Load the saved checkpoint\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "# Load model state\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Scalars for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, parameters in tqdm(train_loader):\n",
        "        images = images.to(device)\n",
        "        parameters = parameters.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            # Encode images using VAE\n",
        "            with torch.no_grad():\n",
        "                vae_images = (vae.encode(images).latent_dist.mode() * 0.18215).float()\n",
        "\n",
        "            # Quantize and unquantize latents\n",
        "            quantized_latents = quantize_batch(vae_images, parameters)\n",
        "            unquantized_latents = unquantize_batch(quantized_latents, parameters)\n",
        "\n",
        "            # Decode the unquantized latents to images\n",
        "            with torch.no_grad():\n",
        "                decoded_unquantized_images = vae.decode(unquantized_latents / 0.18215).sample\n",
        "\n",
        "            # Compute residuals in pixel space\n",
        "            residuals = images - decoded_unquantized_images\n",
        "\n",
        "            # Model prediction\n",
        "            outputs = model(decoded_unquantized_images, parameters)\n",
        "\n",
        "            # Reconstructed images\n",
        "            reconstructed_images = outputs + decoded_unquantized_images\n",
        "\n",
        "            # Normalize the images for VGG\n",
        "            def preprocess_for_vgg(img):\n",
        "                img = (img + 1) / 2  # Scale from [-1,1] to [0,1]\n",
        "                imagenet_mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1).to(device)\n",
        "                imagenet_std = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1).to(device)\n",
        "                img = (img - imagenet_mean) / imagenet_std\n",
        "                return img\n",
        "\n",
        "            output_vgg_input = preprocess_for_vgg(reconstructed_images)\n",
        "            target_vgg_input = preprocess_for_vgg(images)\n",
        "\n",
        "            # Compute losses\n",
        "            mse_loss = criterion_mse(outputs, residuals)\n",
        "            perc_loss = perceptual_loss(output_vgg_input, target_vgg_input)\n",
        "            ms_loss = multi_scale_loss(output_vgg_input, target_vgg_input)\n",
        "            total_loss = mse_loss + 0.01 * perc_loss + 0.1 * ms_loss\n",
        "\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += total_loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.6f}')\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, parameters in val_loader:\n",
        "            images = images.to(device)\n",
        "            parameters = parameters.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                # Encode images using VAE\n",
        "                vae_images = (vae.encode(images).latent_dist.mode() * 0.18215).float()\n",
        "\n",
        "                # Quantize and unquantize latents\n",
        "                quantized_latents = quantize_batch(vae_images, parameters)\n",
        "                unquantized_latents = unquantize_batch(quantized_latents, parameters)\n",
        "\n",
        "                # Decode the unquantized latents to images\n",
        "                decoded_unquantized_images = vae.decode(unquantized_latents / 0.18215).sample\n",
        "\n",
        "                # Compute residuals in pixel space\n",
        "                residuals = images - decoded_unquantized_images\n",
        "\n",
        "                # Model prediction\n",
        "                outputs = model(decoded_unquantized_images, parameters)\n",
        "\n",
        "                # Reconstructed images\n",
        "                reconstructed_images = outputs + decoded_unquantized_images\n",
        "\n",
        "                # Normalize the images for VGG\n",
        "                output_vgg_input = preprocess_for_vgg(reconstructed_images)\n",
        "                target_vgg_input = preprocess_for_vgg(images)\n",
        "\n",
        "                # Compute losses\n",
        "                mse_loss = criterion_mse(outputs, residuals)\n",
        "                perc_loss = perceptual_loss(output_vgg_input, target_vgg_input)\n",
        "                ms_loss = multi_scale_loss(output_vgg_input, target_vgg_input)\n",
        "                total_loss = mse_loss + 0.01 * perc_loss + 0.1 * ms_loss\n",
        "\n",
        "            val_loss += total_loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(val_dataset)\n",
        "    scheduler.step(val_loss)\n",
        "    logging.info(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.6f}, Validation Loss: {val_loss:.6f}')\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.6f}, Validation Loss: {val_loss:.6f}')\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'training_loss': epoch_loss,\n",
        "            'validation_loss': val_loss,\n",
        "        }\n",
        "        torch.save(checkpoint, f'/content/drive/MyDrive/{model_path}/unet_best_checkpoint.pth')\n",
        "        logging.info(f'Best model saved at epoch {epoch+1}')\n",
        "        print(f'Best model saved at epoch {epoch+1}')\n",
        "    checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'training_loss': epoch_loss,\n",
        "            'validation_loss': val_loss,\n",
        "        }\n",
        "    torch.save(checkpoint, f'/content/drive/MyDrive/{model_path}/unet_checkpoint_epoch_{epoch+1}.pth')\n",
        "    logging.info(f'Model checkpoint saved at epoch {epoch+1}')\n",
        "    # Save the model checkpoint periodically\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'training_loss': epoch_loss,\n",
        "            'validation_loss': val_loss,\n",
        "        }\n",
        "        torch.save(checkpoint, f'/content/drive/MyDrive/{model_path}/unet_checkpoint_epoch_{epoch+1}.pth')\n",
        "        logging.info(f'Model checkpoint saved at epoch {epoch+1}')\n",
        "\n",
        "# Save the final model\n",
        "checkpoint = {\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict': scheduler.state_dict(),\n",
        "    'training_loss': epoch_loss,\n",
        "    'validation_loss': val_loss,\n",
        "}\n",
        "torch.save(checkpoint, f'/content/drive/MyDrive/{model_path}/unet_final_checkpoint.pth')\n",
        "logging.info('Final model saved.')\n",
        "\n",
        "# Release GPU memory\n",
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Directory where the images are saved\n",
        "data_dir = '/content/coco_data'\n",
        "\n",
        "# Count the number of files in the directory\n",
        "num_images = len([name for name in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, name))])\n",
        "\n",
        "print(f\"Total number of images downloaded: {num_images}\")\n",
        "\n",
        "# Check if the count matches the expected number\n",
        "if num_images == 10000:\n",
        "    print(\"Successfully downloaded all 10000 images.\")\n",
        "else:\n",
        "    print(f\"Only {num_images} images downloaded, expected 10000.\")\n"
      ],
      "metadata": {
        "id": "k_dCqvccIl6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e7a5ed8e1404b29b6ef141ea67822ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9e649f6b9fe458e9c1b68da0d752fae",
              "IPY_MODEL_2d513d9a86f1475bb40e5ad2710f53f9",
              "IPY_MODEL_279771b7681a493fa698809789cb7ecd"
            ],
            "layout": "IPY_MODEL_3d34778cd5b84fb5893fbe20490d20fc"
          }
        },
        "d9e649f6b9fe458e9c1b68da0d752fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9028bb792b4047d4a78ba10a93b36ead",
            "placeholder": "​",
            "style": "IPY_MODEL_410617b4ea284efbbf36a78f3133c405",
            "value": ""
          }
        },
        "2d513d9a86f1475bb40e5ad2710f53f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8b69b045bf40929d17b0e6c09be2a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_536444cfc5e2463c94fb8c19dbc9fd1a",
            "value": 0
          }
        },
        "279771b7681a493fa698809789cb7ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d882cdf46c54a1aba6d18d3d1d3ebf5",
            "placeholder": "​",
            "style": "IPY_MODEL_4b69025066174a13bcff238daa54ba8a",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "3d34778cd5b84fb5893fbe20490d20fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9028bb792b4047d4a78ba10a93b36ead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410617b4ea284efbbf36a78f3133c405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8b69b045bf40929d17b0e6c09be2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "536444cfc5e2463c94fb8c19dbc9fd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d882cdf46c54a1aba6d18d3d1d3ebf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b69025066174a13bcff238daa54ba8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce79b46483b418798ed4f4f48360fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e80373e39aa47bf944b4ba27fda1fe7",
              "IPY_MODEL_f40ea1032f83410f855ddea89973b8d5",
              "IPY_MODEL_fe8349ab01ef49299884d0a7f37cdb1d"
            ],
            "layout": "IPY_MODEL_5bfc9135090144c6936dca684261b079"
          }
        },
        "6e80373e39aa47bf944b4ba27fda1fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fadb8b52c3c4492a0beacfb5fefd908",
            "placeholder": "​",
            "style": "IPY_MODEL_87203380c93a4086a625aef6933a822b",
            "value": "config.json: 100%"
          }
        },
        "f40ea1032f83410f855ddea89973b8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d3e6c21c1448cf86b9ac4f0eaff524",
            "max": 547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d4c58435ba44ab3b72867c13cb22722",
            "value": 547
          }
        },
        "fe8349ab01ef49299884d0a7f37cdb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02802c36ea1443edacbea197ae4bac92",
            "placeholder": "​",
            "style": "IPY_MODEL_615496d1907c49f5b00860888fbb942e",
            "value": " 547/547 [00:00&lt;00:00, 30.5kB/s]"
          }
        },
        "5bfc9135090144c6936dca684261b079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fadb8b52c3c4492a0beacfb5fefd908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87203380c93a4086a625aef6933a822b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51d3e6c21c1448cf86b9ac4f0eaff524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4c58435ba44ab3b72867c13cb22722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02802c36ea1443edacbea197ae4bac92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615496d1907c49f5b00860888fbb942e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c72a6cc209d14ea480137fa180af31f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbee40da388145ebab51b45fbbdf94aa",
              "IPY_MODEL_dd2c26eaf1fb487198ade76403496577",
              "IPY_MODEL_9a5edd738827425f898bfbb1069cfec2"
            ],
            "layout": "IPY_MODEL_818e963e00c7483d93380657eae7c1ee"
          }
        },
        "fbee40da388145ebab51b45fbbdf94aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a330cbc3cd5a44fd95ca10f1d8ea8361",
            "placeholder": "​",
            "style": "IPY_MODEL_a7c299b82ed147c2b3f8ac195463d068",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "dd2c26eaf1fb487198ade76403496577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aac18aa6f1d4e36a02932f4730690db",
            "max": 334643276,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b11b4d1fbec643629340e75809129b8d",
            "value": 334643276
          }
        },
        "9a5edd738827425f898bfbb1069cfec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddabe319697641ebbec2f5c0a52aa500",
            "placeholder": "​",
            "style": "IPY_MODEL_58d20436267748bc838c64b9e95ecf6e",
            "value": " 335M/335M [00:02&lt;00:00, 212MB/s]"
          }
        },
        "818e963e00c7483d93380657eae7c1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a330cbc3cd5a44fd95ca10f1d8ea8361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c299b82ed147c2b3f8ac195463d068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aac18aa6f1d4e36a02932f4730690db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11b4d1fbec643629340e75809129b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddabe319697641ebbec2f5c0a52aa500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d20436267748bc838c64b9e95ecf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}